17/06/14 18:33:10 INFO SparkContext: Running Spark version 1.6.2
17/06/14 18:33:10 INFO SecurityManager: Changing view acls to: ua40168
17/06/14 18:33:10 INFO SecurityManager: Changing modify acls to: ua40168
17/06/14 18:33:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ua40168); users with modify permissions: Set(ua40168)
17/06/14 18:33:11 INFO Utils: Successfully started service 'sparkDriver' on port 39796.
17/06/14 18:33:11 INFO Slf4jLogger: Slf4jLogger started
17/06/14 18:33:11 INFO Remoting: Starting remoting
17/06/14 18:33:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@140.96.83.36:56786]
17/06/14 18:33:11 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 56786.
17/06/14 18:33:11 INFO SparkEnv: Registering MapOutputTracker
17/06/14 18:33:12 INFO SparkEnv: Registering BlockManagerMaster
17/06/14 18:33:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f7780ff8-8c81-4e2a-8f26-21ee52c5977f
17/06/14 18:33:12 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
17/06/14 18:33:12 INFO SparkEnv: Registering OutputCommitCoordinator
17/06/14 18:33:12 INFO Server: jetty-8.y.z-SNAPSHOT
17/06/14 18:33:12 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
17/06/14 18:33:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/06/14 18:33:12 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://140.96.83.36:4040
17/06/14 18:33:12 INFO Utils: Copying /home/W100.ITRI/ua40168/MF-ALS/rec_itemSimilarity2.py to /tmp/spark-8c331618-aaba-4f31-b347-9f4b0e59488e/userFiles-280c2085-c03a-43de-95bf-4488a6b7fba7/rec_itemSimilarity2.py
17/06/14 18:33:12 INFO SparkContext: Added file file:/home/W100.ITRI/ua40168/MF-ALS/rec_itemSimilarity2.py at file:/home/W100.ITRI/ua40168/MF-ALS/rec_itemSimilarity2.py with timestamp 1497436392470
17/06/14 18:33:12 INFO Executor: Starting executor ID driver on host localhost
17/06/14 18:33:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55191.
17/06/14 18:33:12 INFO NettyBlockTransferService: Server created on 55191
17/06/14 18:33:12 INFO BlockManagerMaster: Trying to register BlockManager
17/06/14 18:33:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55191 with 511.1 MB RAM, BlockManagerId(driver, localhost, 55191)
17/06/14 18:33:12 INFO BlockManagerMaster: Registered BlockManager
17/06/14 18:33:13 INFO EventLoggingListener: Logging events to hdfs:///spark-history/local-1497436392522
begin load model from Model0606
17/06/14 18:33:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 320.8 KB, free 320.8 KB)
17/06/14 18:33:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 348.1 KB)
17/06/14 18:33:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55191 (size: 27.3 KB, free: 511.1 MB)
17/06/14 18:33:13 INFO SparkContext: Created broadcast 0 from textFile at modelSaveLoad.scala:129
17/06/14 18:33:13 INFO FileInputFormat: Total input paths to process : 1
17/06/14 18:33:14 INFO SparkContext: Starting job: first at modelSaveLoad.scala:129
17/06/14 18:33:14 INFO DAGScheduler: Got job 0 (first at modelSaveLoad.scala:129) with 1 output partitions
17/06/14 18:33:14 INFO DAGScheduler: Final stage: ResultStage 0 (first at modelSaveLoad.scala:129)
17/06/14 18:33:14 INFO DAGScheduler: Parents of final stage: List()
17/06/14 18:33:14 INFO DAGScheduler: Missing parents: List()
17/06/14 18:33:14 INFO DAGScheduler: Submitting ResultStage 0 (Model0606/metadata MapPartitionsRDD[1] at textFile at modelSaveLoad.scala:129), which has no missing parents
17/06/14 18:33:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 351.3 KB)
17/06/14 18:33:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1870.0 B, free 353.1 KB)
17/06/14 18:33:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55191 (size: 1870.0 B, free: 511.1 MB)
17/06/14 18:33:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1008
17/06/14 18:33:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (Model0606/metadata MapPartitionsRDD[1] at textFile at modelSaveLoad.scala:129)
17/06/14 18:33:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/06/14 18:33:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,ANY, 2233 bytes)
17/06/14 18:33:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/06/14 18:33:14 INFO Executor: Fetching file:/home/W100.ITRI/ua40168/MF-ALS/rec_itemSimilarity2.py with timestamp 1497436392470
17/06/14 18:33:14 INFO Utils: /home/W100.ITRI/ua40168/MF-ALS/rec_itemSimilarity2.py has been previously copied to /tmp/spark-8c331618-aaba-4f31-b347-9f4b0e59488e/userFiles-280c2085-c03a-43de-95bf-4488a6b7fba7/rec_itemSimilarity2.py
17/06/14 18:33:14 INFO HadoopRDD: Input split: hdfs://itrihd34:8020/user/ua40168/Model0606/metadata/part-00000:0+50
17/06/14 18:33:14 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/06/14 18:33:14 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/06/14 18:33:14 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/06/14 18:33:14 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/06/14 18:33:14 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/06/14 18:33:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2147 bytes result sent to driver
17/06/14 18:33:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 198 ms on localhost (1/1)
17/06/14 18:33:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/06/14 18:33:14 INFO DAGScheduler: ResultStage 0 (first at modelSaveLoad.scala:129) finished in 0.215 s
17/06/14 18:33:14 INFO DAGScheduler: Job 0 finished: first at modelSaveLoad.scala:129, took 0.276840 s
17/06/14 18:33:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 320.9 KB, free 674.0 KB)
17/06/14 18:33:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.3 KB, free 701.3 KB)
17/06/14 18:33:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55191 (size: 27.3 KB, free: 511.1 MB)
17/06/14 18:33:14 INFO SparkContext: Created broadcast 2 from textFile at modelSaveLoad.scala:129
17/06/14 18:33:14 INFO FileInputFormat: Total input paths to process : 1
17/06/14 18:33:14 INFO SparkContext: Starting job: first at modelSaveLoad.scala:129
17/06/14 18:33:14 INFO DAGScheduler: Got job 1 (first at modelSaveLoad.scala:129) with 1 output partitions
17/06/14 18:33:14 INFO DAGScheduler: Final stage: ResultStage 1 (first at modelSaveLoad.scala:129)
17/06/14 18:33:14 INFO DAGScheduler: Parents of final stage: List()
17/06/14 18:33:14 INFO DAGScheduler: Missing parents: List()
17/06/14 18:33:14 INFO DAGScheduler: Submitting ResultStage 1 (Model0606/metadata MapPartitionsRDD[3] at textFile at modelSaveLoad.scala:129), which has no missing parents
17/06/14 18:33:14 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.2 KB, free 704.4 KB)
17/06/14 18:33:14 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1872.0 B, free 706.3 KB)
17/06/14 18:33:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:55191 (size: 1872.0 B, free: 511.1 MB)
17/06/14 18:33:14 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1008
17/06/14 18:33:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (Model0606/metadata MapPartitionsRDD[3] at textFile at modelSaveLoad.scala:129)
17/06/14 18:33:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/06/14 18:33:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,ANY, 2233 bytes)
17/06/14 18:33:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/06/14 18:33:14 INFO HadoopRDD: Input split: hdfs://itrihd34:8020/user/ua40168/Model0606/metadata/part-00000:0+50
17/06/14 18:33:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2202 bytes result sent to driver
17/06/14 18:33:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 15 ms on localhost (1/1)
17/06/14 18:33:14 INFO DAGScheduler: ResultStage 1 (first at modelSaveLoad.scala:129) finished in 0.015 s
17/06/14 18:33:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/06/14 18:33:14 INFO DAGScheduler: Job 1 finished: first at modelSaveLoad.scala:129, took 0.025029 s
17/06/14 18:33:14 INFO ParquetRelation: Listing hdfs://itrihd34:8020/user/ua40168/Model0606/data/user on driver
17/06/14 18:33:14 INFO SparkContext: Starting job: parquet at MatrixFactorizationModel.scala:372
17/06/14 18:33:14 INFO DAGScheduler: Got job 2 (parquet at MatrixFactorizationModel.scala:372) with 12 output partitions
17/06/14 18:33:14 INFO DAGScheduler: Final stage: ResultStage 2 (parquet at MatrixFactorizationModel.scala:372)
17/06/14 18:33:14 INFO DAGScheduler: Parents of final stage: List()
17/06/14 18:33:14 INFO DAGScheduler: Missing parents: List()
17/06/14 18:33:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at parquet at MatrixFactorizationModel.scala:372), which has no missing parents
17/06/14 18:33:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 80.1 KB, free 786.3 KB)
17/06/14 18:33:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 28.7 KB, free 815.0 KB)
17/06/14 18:33:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:55191 (size: 28.7 KB, free: 511.0 MB)
17/06/14 18:33:14 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1008
17/06/14 18:33:14 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at parquet at MatrixFactorizationModel.scala:372)
17/06/14 18:33:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 12 tasks
17/06/14 18:33:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4, localhost, partition 2,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5, localhost, partition 3,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6, localhost, partition 4,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 7, localhost, partition 5,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 8, localhost, partition 6,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 9, localhost, partition 7,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 10, localhost, partition 8,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 11, localhost, partition 9,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 12, localhost, partition 10,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:14 INFO TaskSetManager: Starting task 11.0 in stage 2.0 (TID 13, localhost, partition 11,PROCESS_LOCAL, 2280 bytes)
17/06/14 18:33:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/06/14 18:33:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/06/14 18:33:14 INFO Executor: Running task 2.0 in stage 2.0 (TID 4)
17/06/14 18:33:14 INFO Executor: Running task 3.0 in stage 2.0 (TID 5)
17/06/14 18:33:14 INFO Executor: Running task 5.0 in stage 2.0 (TID 7)
17/06/14 18:33:14 INFO Executor: Running task 6.0 in stage 2.0 (TID 8)
17/06/14 18:33:14 INFO Executor: Running task 7.0 in stage 2.0 (TID 9)
17/06/14 18:33:14 INFO Executor: Running task 8.0 in stage 2.0 (TID 10)
17/06/14 18:33:14 INFO Executor: Running task 4.0 in stage 2.0 (TID 6)
17/06/14 18:33:14 INFO Executor: Running task 9.0 in stage 2.0 (TID 11)
17/06/14 18:33:14 INFO Executor: Running task 10.0 in stage 2.0 (TID 12)
17/06/14 18:33:14 INFO Executor: Running task 11.0 in stage 2.0 (TID 13)
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:14 INFO Executor: Finished task 2.0 in stage 2.0 (TID 4). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 3.0 in stage 2.0 (TID 5). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 9.0 in stage 2.0 (TID 11). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 7.0 in stage 2.0 (TID 9). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 8.0 in stage 2.0 (TID 10). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 6.0 in stage 2.0 (TID 8). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 10.0 in stage 2.0 (TID 12). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 4.0 in stage 2.0 (TID 6). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 5.0 in stage 2.0 (TID 7). 936 bytes result sent to driver
17/06/14 18:33:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 936 bytes result sent to driver
17/06/14 18:33:14 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 91 ms on localhost (1/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 90 ms on localhost (2/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 11) in 87 ms on localhost (3/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 9) in 90 ms on localhost (4/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 100 ms on localhost (5/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 10) in 90 ms on localhost (6/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 8) in 92 ms on localhost (7/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 12) in 90 ms on localhost (8/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 95 ms on localhost (9/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 7) in 95 ms on localhost (10/12)
17/06/14 18:33:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 97 ms on localhost (11/12)
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
17/06/14 18:33:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:55191 in memory (size: 1872.0 B, free: 511.0 MB)
17/06/14 18:33:15 INFO ContextCleaner: Cleaned accumulator 3
17/06/14 18:33:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:55191 in memory (size: 27.3 KB, free: 511.1 MB)
17/06/14 18:33:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:55191 in memory (size: 1870.0 B, free: 511.1 MB)
17/06/14 18:33:15 INFO ContextCleaner: Cleaned accumulator 2
17/06/14 18:33:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:55191 in memory (size: 27.3 KB, free: 511.1 MB)
17/06/14 18:33:15 INFO Executor: Finished task 11.0 in stage 2.0 (TID 13). 1792 bytes result sent to driver
17/06/14 18:33:15 INFO TaskSetManager: Finished task 11.0 in stage 2.0 (TID 13) in 794 ms on localhost (12/12)
17/06/14 18:33:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/06/14 18:33:15 INFO DAGScheduler: ResultStage 2 (parquet at MatrixFactorizationModel.scala:372) finished in 0.806 s
17/06/14 18:33:15 INFO DAGScheduler: Job 2 finished: parquet at MatrixFactorizationModel.scala:372, took 0.850706 s
17/06/14 18:33:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 82.9 KB, free 191.7 KB)
17/06/14 18:33:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 27.2 KB, free 218.9 KB)
17/06/14 18:33:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:55191 (size: 27.2 KB, free: 511.1 MB)
17/06/14 18:33:15 INFO SparkContext: Created broadcast 5 from map at MatrixFactorizationModel.scala:373
17/06/14 18:33:15 INFO ParquetRelation: Listing hdfs://itrihd34:8020/user/ua40168/Model0606/data/product on driver
17/06/14 18:33:15 INFO SparkContext: Starting job: parquet at MatrixFactorizationModel.scala:376
17/06/14 18:33:15 INFO DAGScheduler: Got job 3 (parquet at MatrixFactorizationModel.scala:376) with 12 output partitions
17/06/14 18:33:15 INFO DAGScheduler: Final stage: ResultStage 3 (parquet at MatrixFactorizationModel.scala:376)
17/06/14 18:33:15 INFO DAGScheduler: Parents of final stage: List()
17/06/14 18:33:15 INFO DAGScheduler: Missing parents: List()
17/06/14 18:33:15 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[10] at parquet at MatrixFactorizationModel.scala:376), which has no missing parents
17/06/14 18:33:15 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 80.1 KB, free 299.0 KB)
17/06/14 18:33:15 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.7 KB, free 327.7 KB)
17/06/14 18:33:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:55191 (size: 28.7 KB, free: 511.0 MB)
17/06/14 18:33:15 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1008
17/06/14 18:33:15 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 3 (MapPartitionsRDD[10] at parquet at MatrixFactorizationModel.scala:376)
17/06/14 18:33:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 12 tasks
17/06/14 18:33:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 16, localhost, partition 2,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 17, localhost, partition 3,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 18, localhost, partition 4,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 19, localhost, partition 5,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 20, localhost, partition 6,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 21, localhost, partition 7,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 22, localhost, partition 8,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 23, localhost, partition 9,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 24, localhost, partition 10,PROCESS_LOCAL, 2144 bytes)
17/06/14 18:33:15 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 25, localhost, partition 11,PROCESS_LOCAL, 2283 bytes)
17/06/14 18:33:15 INFO Executor: Running task 1.0 in stage 3.0 (TID 15)
17/06/14 18:33:15 INFO Executor: Running task 4.0 in stage 3.0 (TID 18)
17/06/14 18:33:15 INFO Executor: Running task 7.0 in stage 3.0 (TID 21)
17/06/14 18:33:15 INFO Executor: Running task 8.0 in stage 3.0 (TID 22)
17/06/14 18:33:15 INFO Executor: Running task 10.0 in stage 3.0 (TID 24)
17/06/14 18:33:15 INFO Executor: Running task 6.0 in stage 3.0 (TID 20)
17/06/14 18:33:15 INFO Executor: Running task 5.0 in stage 3.0 (TID 19)
17/06/14 18:33:15 INFO Executor: Running task 0.0 in stage 3.0 (TID 14)
17/06/14 18:33:15 INFO Executor: Running task 2.0 in stage 3.0 (TID 16)
17/06/14 18:33:15 INFO Executor: Running task 9.0 in stage 3.0 (TID 23)
17/06/14 18:33:15 INFO Executor: Running task 3.0 in stage 3.0 (TID 17)
17/06/14 18:33:15 INFO Executor: Running task 11.0 in stage 3.0 (TID 25)
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO Executor: Finished task 4.0 in stage 3.0 (TID 18). 936 bytes result sent to driver
17/06/14 18:33:15 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 18) in 18 ms on localhost (1/12)
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO Executor: Finished task 6.0 in stage 3.0 (TID 20). 936 bytes result sent to driver
17/06/14 18:33:15 INFO Executor: Finished task 3.0 in stage 3.0 (TID 17). 936 bytes result sent to driver
17/06/14 18:33:15 INFO Executor: Finished task 5.0 in stage 3.0 (TID 19). 936 bytes result sent to driver
17/06/14 18:33:15 INFO Executor: Finished task 8.0 in stage 3.0 (TID 22). 936 bytes result sent to driver
17/06/14 18:33:15 INFO Executor: Finished task 0.0 in stage 3.0 (TID 14). 936 bytes result sent to driver
17/06/14 18:33:15 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 17) in 29 ms on localhost (2/12)
17/06/14 18:33:15 INFO Executor: Finished task 9.0 in stage 3.0 (TID 23). 936 bytes result sent to driver
17/06/14 18:33:15 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 22) in 32 ms on localhost (3/12)
17/06/14 18:33:15 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 20) in 33 ms on localhost (4/12)
17/06/14 18:33:15 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 19) in 33 ms on localhost (5/12)
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 14) in 37 ms on localhost (6/12)
17/06/14 18:33:15 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 23) in 34 ms on localhost (7/12)
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO Executor: Finished task 2.0 in stage 3.0 (TID 16). 936 bytes result sent to driver
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:15 INFO Executor: Finished task 1.0 in stage 3.0 (TID 15). 936 bytes result sent to driver
17/06/14 18:33:15 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 16) in 40 ms on localhost (8/12)
17/06/14 18:33:15 INFO Executor: Finished task 10.0 in stage 3.0 (TID 24). 936 bytes result sent to driver
17/06/14 18:33:15 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 15) in 42 ms on localhost (9/12)
17/06/14 18:33:15 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 24) in 38 ms on localhost (10/12)
17/06/14 18:33:16 INFO ParquetFileReader: Initiating action with parallelism: 5
17/06/14 18:33:16 INFO Executor: Finished task 11.0 in stage 3.0 (TID 25). 1792 bytes result sent to driver
17/06/14 18:33:16 INFO Executor: Finished task 7.0 in stage 3.0 (TID 21). 936 bytes result sent to driver
17/06/14 18:33:16 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 21) in 42 ms on localhost (11/12)
17/06/14 18:33:16 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 25) in 40 ms on localhost (12/12)
17/06/14 18:33:16 INFO DAGScheduler: ResultStage 3 (parquet at MatrixFactorizationModel.scala:376) finished in 0.046 s
17/06/14 18:33:16 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/06/14 18:33:16 INFO DAGScheduler: Job 3 finished: parquet at MatrixFactorizationModel.scala:376, took 0.094694 s
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 320.5 KB, free 648.2 KB)
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 27.2 KB, free 675.5 KB)
17/06/14 18:33:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:55191 (size: 27.2 KB, free: 511.0 MB)
17/06/14 18:33:16 INFO SparkContext: Created broadcast 7 from map at MatrixFactorizationModel.scala:377
17/06/14 18:33:16 INFO deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
17/06/14 18:33:16 INFO ParquetRelation: Reading Parquet file(s) from hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00000-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00001-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00002-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00003-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00004-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00005-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00006-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00007-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00008-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00009-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00010-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00011-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet
17/06/14 18:33:16 INFO SparkContext: Starting job: first at MatrixFactorizationModel.scala:67
17/06/14 18:33:16 INFO DAGScheduler: Got job 4 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
17/06/14 18:33:16 INFO DAGScheduler: Final stage: ResultStage 4 (first at MatrixFactorizationModel.scala:67)
17/06/14 18:33:16 INFO DAGScheduler: Parents of final stage: List()
17/06/14 18:33:16 INFO DAGScheduler: Missing parents: List()
17/06/14 18:33:16 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[8] at map at MatrixFactorizationModel.scala:373), which has no missing parents
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 4.8 KB, free 680.3 KB)
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 683.0 KB)
17/06/14 18:33:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:55191 (size: 2.8 KB, free: 511.0 MB)
17/06/14 18:33:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1008
17/06/14 18:33:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[8] at map at MatrixFactorizationModel.scala:373)
17/06/14 18:33:16 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/06/14 18:33:16 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 26, localhost, partition 0,ANY, 2312 bytes)
17/06/14 18:33:16 INFO Executor: Running task 0.0 in stage 4.0 (TID 26)
17/06/14 18:33:16 INFO ParquetRelation$$anonfun$buildInternalScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00000-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet start: 0 end: 1390015 length: 1390015 hosts: []}
17/06/14 18:33:16 WARN ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
17/06/14 18:33:16 INFO CatalystReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional int32 id;
  optional group features (LIST) {
    repeated group list {
      optional double element;
    }
  }
}

Catalyst form:
StructType(StructField(id,IntegerType,true), StructField(features,ArrayType(DoubleType,true),true))
       
17/06/14 18:33:16 INFO GenerateUnsafeProjection: Code generated in 126.151002 ms
17/06/14 18:33:16 INFO InternalParquetRecordReader: RecordReader initialized will read a total of 12829 records.
17/06/14 18:33:16 INFO InternalParquetRecordReader: at row 0. reading next block
17/06/14 18:33:16 INFO ZlibFactory: Successfully loaded & initialized native-zlib library
17/06/14 18:33:16 INFO CodecPool: Got brand-new decompressor [.gz]
17/06/14 18:33:16 INFO InternalParquetRecordReader: block read in memory in 18 ms. row count = 12829
17/06/14 18:33:16 INFO Executor: Finished task 0.0 in stage 4.0 (TID 26). 2463 bytes result sent to driver
17/06/14 18:33:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 26) in 331 ms on localhost (1/1)
17/06/14 18:33:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/06/14 18:33:16 INFO DAGScheduler: ResultStage 4 (first at MatrixFactorizationModel.scala:67) finished in 0.332 s
17/06/14 18:33:16 INFO DAGScheduler: Job 4 finished: first at MatrixFactorizationModel.scala:67, took 0.343149 s
17/06/14 18:33:16 WARN MatrixFactorizationModel: User factor does not have a partitioner. Prediction on individual records could be slow.
17/06/14 18:33:16 WARN MatrixFactorizationModel: User factor is not cached. Prediction could be slow.
17/06/14 18:33:16 INFO ParquetRelation: Reading Parquet file(s) from hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00000-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00001-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00002-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00003-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00004-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00005-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00006-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00007-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00008-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00009-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00010-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet, hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00011-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet
17/06/14 18:33:16 INFO SparkContext: Starting job: first at MatrixFactorizationModel.scala:67
17/06/14 18:33:16 INFO DAGScheduler: Got job 5 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
17/06/14 18:33:16 INFO DAGScheduler: Final stage: ResultStage 5 (first at MatrixFactorizationModel.scala:67)
17/06/14 18:33:16 INFO DAGScheduler: Parents of final stage: List()
17/06/14 18:33:16 INFO DAGScheduler: Missing parents: List()
17/06/14 18:33:16 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[13] at map at MatrixFactorizationModel.scala:377), which has no missing parents
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 4.8 KB, free 687.8 KB)
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.8 KB, free 690.6 KB)
17/06/14 18:33:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:55191 (size: 2.8 KB, free: 511.0 MB)
17/06/14 18:33:16 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1008
17/06/14 18:33:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at MatrixFactorizationModel.scala:377)
17/06/14 18:33:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/06/14 18:33:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 27, localhost, partition 0,ANY, 2316 bytes)
17/06/14 18:33:16 INFO Executor: Running task 0.0 in stage 5.0 (TID 27)
17/06/14 18:33:16 INFO ParquetRelation$$anonfun$buildInternalScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00000-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet start: 0 end: 892692 length: 892692 hosts: []}
17/06/14 18:33:16 WARN ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
17/06/14 18:33:16 INFO CatalystReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional int32 id;
  optional group features (LIST) {
    repeated group list {
      optional double element;
    }
  }
}

Catalyst form:
StructType(StructField(id,IntegerType,true), StructField(features,ArrayType(DoubleType,true),true))
       
17/06/14 18:33:16 INFO InternalParquetRecordReader: RecordReader initialized will read a total of 8132 records.
17/06/14 18:33:16 INFO InternalParquetRecordReader: at row 0. reading next block
17/06/14 18:33:16 INFO InternalParquetRecordReader: block read in memory in 2 ms. row count = 8132
17/06/14 18:33:16 INFO Executor: Finished task 0.0 in stage 5.0 (TID 27). 2463 bytes result sent to driver
17/06/14 18:33:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 27) in 31 ms on localhost (1/1)
17/06/14 18:33:16 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/06/14 18:33:16 INFO DAGScheduler: ResultStage 5 (first at MatrixFactorizationModel.scala:67) finished in 0.031 s
17/06/14 18:33:16 INFO DAGScheduler: Job 5 finished: first at MatrixFactorizationModel.scala:67, took 0.040109 s
17/06/14 18:33:16 WARN MatrixFactorizationModel: Product factor does not have a partitioner. Prediction on individual records could be slow.
17/06/14 18:33:16 WARN MatrixFactorizationModel: Product factor is not cached. Prediction could be slow.
17/06/14 18:33:16 INFO SparkContext: Starting job: first at MatrixFactorizationModel.scala:67
17/06/14 18:33:16 INFO DAGScheduler: Got job 6 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
17/06/14 18:33:16 INFO DAGScheduler: Final stage: ResultStage 6 (first at MatrixFactorizationModel.scala:67)
17/06/14 18:33:16 INFO DAGScheduler: Parents of final stage: List()
17/06/14 18:33:16 INFO DAGScheduler: Missing parents: List()
17/06/14 18:33:16 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[8] at map at MatrixFactorizationModel.scala:373), which has no missing parents
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 4.8 KB, free 695.4 KB)
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.8 KB, free 698.2 KB)
17/06/14 18:33:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:55191 (size: 2.8 KB, free: 511.0 MB)
17/06/14 18:33:16 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1008
17/06/14 18:33:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[8] at map at MatrixFactorizationModel.scala:373)
17/06/14 18:33:16 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/06/14 18:33:16 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 28, localhost, partition 0,ANY, 2312 bytes)
17/06/14 18:33:16 INFO Executor: Running task 0.0 in stage 6.0 (TID 28)
17/06/14 18:33:16 INFO ParquetRelation$$anonfun$buildInternalScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://itrihd34:8020/user/ua40168/Model0606/data/user/part-r-00000-39930e3a-dd27-43a2-93a8-02a91c4fbaed.gz.parquet start: 0 end: 1390015 length: 1390015 hosts: []}
17/06/14 18:33:16 WARN ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
17/06/14 18:33:16 INFO CatalystReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional int32 id;
  optional group features (LIST) {
    repeated group list {
      optional double element;
    }
  }
}

Catalyst form:
StructType(StructField(id,IntegerType,true), StructField(features,ArrayType(DoubleType,true),true))
       
17/06/14 18:33:16 INFO InternalParquetRecordReader: RecordReader initialized will read a total of 12829 records.
17/06/14 18:33:16 INFO InternalParquetRecordReader: at row 0. reading next block
17/06/14 18:33:16 INFO InternalParquetRecordReader: block read in memory in 2 ms. row count = 12829
17/06/14 18:33:16 INFO Executor: Finished task 0.0 in stage 6.0 (TID 28). 2463 bytes result sent to driver
17/06/14 18:33:16 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 28) in 30 ms on localhost (1/1)
17/06/14 18:33:16 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/06/14 18:33:16 INFO DAGScheduler: ResultStage 6 (first at MatrixFactorizationModel.scala:67) finished in 0.030 s
17/06/14 18:33:16 INFO DAGScheduler: Job 6 finished: first at MatrixFactorizationModel.scala:67, took 0.037626 s
17/06/14 18:33:16 WARN MatrixFactorizationModelWrapper: User factor does not have a partitioner. Prediction on individual records could be slow.
17/06/14 18:33:16 WARN MatrixFactorizationModelWrapper: User factor is not cached. Prediction could be slow.
17/06/14 18:33:16 INFO SparkContext: Starting job: first at MatrixFactorizationModel.scala:67
17/06/14 18:33:16 INFO DAGScheduler: Got job 7 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
17/06/14 18:33:16 INFO DAGScheduler: Final stage: ResultStage 7 (first at MatrixFactorizationModel.scala:67)
17/06/14 18:33:16 INFO DAGScheduler: Parents of final stage: List()
17/06/14 18:33:16 INFO DAGScheduler: Missing parents: List()
17/06/14 18:33:16 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[13] at map at MatrixFactorizationModel.scala:377), which has no missing parents
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 4.8 KB, free 703.0 KB)
17/06/14 18:33:16 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.8 KB, free 705.7 KB)
17/06/14 18:33:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:55191 (size: 2.8 KB, free: 511.0 MB)
17/06/14 18:33:16 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1008
17/06/14 18:33:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[13] at map at MatrixFactorizationModel.scala:377)
17/06/14 18:33:16 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/06/14 18:33:16 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 29, localhost, partition 0,ANY, 2316 bytes)
17/06/14 18:33:16 INFO Executor: Running task 0.0 in stage 7.0 (TID 29)
17/06/14 18:33:16 INFO ParquetRelation$$anonfun$buildInternalScan$1$$anon$1: Input split: ParquetInputSplit{part: hdfs://itrihd34:8020/user/ua40168/Model0606/data/product/part-r-00000-c184bd01-67c8-4cae-a6e8-4651ae534669.gz.parquet start: 0 end: 892692 length: 892692 hosts: []}
17/06/14 18:33:16 WARN ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
17/06/14 18:33:16 INFO CatalystReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional int32 id;
  optional group features (LIST) {
    repeated group list {
      optional double element;
    }
  }
}

Catalyst form:
StructType(StructField(id,IntegerType,true), StructField(features,ArrayType(DoubleType,true),true))
       
17/06/14 18:33:16 INFO InternalParquetRecordReader: RecordReader initialized will read a total of 8132 records.
17/06/14 18:33:16 INFO InternalParquetRecordReader: at row 0. reading next block
17/06/14 18:33:16 INFO InternalParquetRecordReader: block read in memory in 1 ms. row count = 8132
17/06/14 18:33:16 INFO Executor: Finished task 0.0 in stage 7.0 (TID 29). 2463 bytes result sent to driver
17/06/14 18:33:16 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 29) in 28 ms on localhost (1/1)
17/06/14 18:33:16 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/06/14 18:33:16 INFO DAGScheduler: ResultStage 7 (first at MatrixFactorizationModel.scala:67) finished in 0.028 s
17/06/14 18:33:16 INFO DAGScheduler: Job 7 finished: first at MatrixFactorizationModel.scala:67, took 0.036363 s
17/06/14 18:33:16 WARN MatrixFactorizationModelWrapper: Product factor does not have a partitioner. Prediction on individual records could be slow.
17/06/14 18:33:16 WARN MatrixFactorizationModelWrapper: Product factor is not cached. Prediction could be slow.
recommendProductsForUsers 10
Traceback (most recent call last):
  File "/home/W100.ITRI/ua40168/MF-ALS/rec_itemSimilarity2.py", line 55, in <module>
    pFeatures = model.productFeatures().toDF()
AttributeError: 'PipelinedRDD' object has no attribute 'toDF'
17/06/14 18:33:16 INFO SparkContext: Invoking stop() from shutdown hook
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
17/06/14 18:33:16 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
17/06/14 18:33:16 INFO SparkUI: Stopped Spark web UI at http://140.96.83.36:4040
17/06/14 18:33:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/06/14 18:33:17 INFO MemoryStore: MemoryStore cleared
17/06/14 18:33:17 INFO BlockManager: BlockManager stopped
17/06/14 18:33:17 INFO BlockManagerMaster: BlockManagerMaster stopped
17/06/14 18:33:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/06/14 18:33:17 INFO SparkContext: Successfully stopped SparkContext
17/06/14 18:33:17 INFO ShutdownHookManager: Shutdown hook called
17/06/14 18:33:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-8c331618-aaba-4f31-b347-9f4b0e59488e/pyspark-951820f0-0c8e-4c1b-9dc4-d3fd85b55e04
17/06/14 18:33:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-8c331618-aaba-4f31-b347-9f4b0e59488e
17/06/14 18:33:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/06/14 18:33:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/06/14 18:33:17 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
